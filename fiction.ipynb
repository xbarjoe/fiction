{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.datasets import load_files\n",
    "from keras.utils import np_utils\n",
    "from sklearn.model_selection import train_test_split\n",
    "from keras.preprocessing.image import array_to_img, img_to_array, load_img\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Conv2D,MaxPooling2D\n",
    "from keras.layers import Activation, Dense, Flatten, Dropout\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.callbacks import ModelCheckpoint\n",
    "from keras import backend as K\n",
    "from PIL import Image\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "import cv2\n",
    "import dlab\n",
    "from skimage import transform"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data='/Users/stephenowen/Desktop/395/final/fiction/fruits-360/Training'\n",
    "test_data='/Users/stephenowen/Desktop/395/final/fiction/fruits-360/Test'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_data(path):\n",
    "    data = load_files(path)\n",
    "    files = np.array(data['filenames'])\n",
    "    targets = np.array(data['target'])\n",
    "    target_labels = np.array(data['target_names'])\n",
    "    return files,targets,target_labels\n",
    "\n",
    "X_train, Y_train, labels = get_data(train_data)\n",
    "X_test, Y_test,_ = get_data(test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y_train = np_utils.to_categorical(Y_train, 120)\n",
    "Y_test = np_utils.to_categorical(Y_test, 120)\n",
    "X_train, X_val = train_test_split(X_train, test_size=0.2, random_state=33)\n",
    "Y_train, Y_val = train_test_split(Y_train, test_size=0.2, random_state=33)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_image_to_array(files):\n",
    "    images_as_array=[]\n",
    "    for file in files:\n",
    "        images_as_array.append(img_to_array(load_img(file)))\n",
    "    return images_as_array\n",
    "\n",
    "X_train = np.array(convert_image_to_array(X_train))\n",
    "X_val = np.array(convert_image_to_array(X_val))\n",
    "X_test = np.array(convert_image_to_array(X_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = X_train.astype('float32')/255\n",
    "X_val = X_val.astype('float32')/255\n",
    "X_test = X_test.astype('float32')/255"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_1 (Conv2D)            (None, 100, 100, 16)      208       \n",
      "_________________________________________________________________\n",
      "activation_1 (Activation)    (None, 100, 100, 16)      0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2 (None, 50, 50, 16)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_2 (Conv2D)            (None, 50, 50, 32)        2080      \n",
      "_________________________________________________________________\n",
      "max_pooling2d_2 (MaxPooling2 (None, 25, 25, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_3 (Conv2D)            (None, 25, 25, 64)        8256      \n",
      "_________________________________________________________________\n",
      "max_pooling2d_3 (MaxPooling2 (None, 12, 12, 64)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_4 (Conv2D)            (None, 12, 12, 128)       32896     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_4 (MaxPooling2 (None, 6, 6, 128)         0         \n",
      "_________________________________________________________________\n",
      "conv2d_5 (Conv2D)            (None, 6, 6, 256)         131328    \n",
      "_________________________________________________________________\n",
      "max_pooling2d_5 (MaxPooling2 (None, 3, 3, 256)         0         \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 3, 3, 256)         0         \n",
      "_________________________________________________________________\n",
      "flatten_1 (Flatten)          (None, 2304)              0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 150)               345750    \n",
      "_________________________________________________________________\n",
      "activation_2 (Activation)    (None, 150)               0         \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 150)               0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 120)               18120     \n",
      "=================================================================\n",
      "Total params: 538,638\n",
      "Trainable params: 538,638\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = Sequential()\n",
    "\n",
    "model.add(Conv2D(filters = 16, kernel_size = 2,input_shape=(100,100,3),padding='same'))\n",
    "model.add(Activation('relu'))\n",
    "model.add(MaxPooling2D(pool_size=2))\n",
    "\n",
    "model.add(Conv2D(filters = 32,kernel_size = 2,activation= 'relu',padding='same'))\n",
    "model.add(MaxPooling2D(pool_size=2))\n",
    "\n",
    "model.add(Conv2D(filters = 64,kernel_size = 2,activation= 'relu',padding='same'))\n",
    "model.add(MaxPooling2D(pool_size=2))\n",
    "\n",
    "model.add(Conv2D(filters = 128,kernel_size = 2,activation= 'relu',padding='same'))\n",
    "model.add(MaxPooling2D(pool_size=2))\n",
    "\n",
    "model.add(Conv2D(filters = 256,kernel_size = 2,activation= 'relu',padding='same'))\n",
    "model.add(MaxPooling2D(pool_size=2))\n",
    "# specifying parameters for fully connected layer\n",
    "model.add(Dropout(0.3))\n",
    "model.add(Flatten())\n",
    "model.add(Dense(150))\n",
    "model.add(Activation('relu'))\n",
    "model.add(Dropout(0.4))\n",
    "model.add(Dense(120,activation = 'softmax'))\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss='categorical_crossentropy',\n",
    "              optimizer='adam',\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "checkpointer = ModelCheckpoint(filepath = 'cnn_from_scratch_fruits_adam.hdf5', verbose = 1, save_best_only = True)\n",
    "\n",
    "# running \n",
    "CNN_model = model.fit(X_train,Y_train,\n",
    "        batch_size = 120,\n",
    "        epochs=20,\n",
    "        validation_data=(X_val, Y_val),\n",
    "        callbacks = [checkpointer],\n",
    "        verbose=2, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.load_weights('cnn_from_scratch_fruits_adam.hdf5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20622/20622 [==============================] - 15s 714us/step\n",
      "Test accuracy: 0.9890408515930176\n"
     ]
    }
   ],
   "source": [
    "score = model.evaluate(X_test, Y_test)\n",
    "print('Test accuracy:', score[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load(filename):\n",
    "    #img = cv2.imread(filename)\n",
    "    #gray_img = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "    #_, thresh = cv2.threshold(gray_img, 127, 255, cv2.THRESH_BINARY_INV + cv2.THRESH_TRUNC)\n",
    "    #img_contours = cv2.findContours(thresh, cv2.RETR_TREE, cv2.CHAIN_APPROX_SIMPLE)[-2]\n",
    "    #img_contours = sorted(img_contours, key=cv2.contourArea)\n",
    "\n",
    "    #for i in img_contours:\n",
    "    #    if cv2.contourArea(i) > 100:\n",
    "    #        break\n",
    "    #mask = np.zeros(img.shape[:2], np.uint8)\n",
    "    #cv2.drawContours(mask, [i],-1, 255, -1)\n",
    "    #new_img = cv2.bitwise_and(img, img, mask=mask)\n",
    "    #cv2.imwrite('/Users/stephenowen/Desktop/395/final/fiction/out.jpg', new_img) \n",
    "\n",
    "    \n",
    "    np_image = np.read(filename)\n",
    "    np_image = np.array(np_image).astype('float32')/255\n",
    "    np_image = transform.resize(np_image, (100, 100, 3))\n",
    "    np_image = np.expand_dims(np_image, axis=0)\n",
    "    \n",
    "   \n",
    "    return np_image\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "module 'numpy' has no attribute 'read'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-25-5c0ecf963316>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mimage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'./fruits-360/test-multiple_fruits/apple_pear.jpg'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlabels\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0margmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-24-257f6ebc7ace>\u001b[0m in \u001b[0;36mload\u001b[0;34m(filename)\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 17\u001b[0;31m     \u001b[0mnp_image\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilename\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     18\u001b[0m     \u001b[0mnp_image\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp_image\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'float32'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0;36m255\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m     \u001b[0mnp_image\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtransform\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mresize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp_image\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;36m100\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m100\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m3\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages/numpy/__init__.py\u001b[0m in \u001b[0;36m__getattr__\u001b[0;34m(attr)\u001b[0m\n\u001b[1;32m    218\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    219\u001b[0m                 raise AttributeError(\"module {!r} has no attribute \"\n\u001b[0;32m--> 220\u001b[0;31m                                      \"{!r}\".format(__name__, attr))\n\u001b[0m\u001b[1;32m    221\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    222\u001b[0m         \u001b[0;32mdef\u001b[0m \u001b[0m__dir__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAttributeError\u001b[0m: module 'numpy' has no attribute 'read'"
     ]
    }
   ],
   "source": [
    " image = load('./fruits-360/test-multiple_fruits/apple_pear.jpg')\n",
    "x=model.predict(image)\n",
    "print(labels[np.argmax(x)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# using model to predict on test data\n",
    "Y_pred = model.predict(X_test)\n",
    "fig = plt.figure(figsize=(20, 15))\n",
    "for i, idx in enumerate(np.random.choice(X_test.shape[0], size=25, replace=False)):\n",
    "    ax = fig.add_subplot(5, 5, i + 1, xticks=[], yticks=[])\n",
    "    ax.imshow(np.squeeze(X_test[idx]))\n",
    "    pred_idx = np.argmax(Y_pred[idx])\n",
    "    true_idx = np.argmax(Y_test[idx])\n",
    "    ax.set_title(\"{} ({})\".format(labels[pred_idx], labels[true_idx]),\n",
    "                 color=(\"green\" if pred_idx == true_idx else \"red\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(1, figsize = (10, 10))  \n",
    "plt.subplot(211)  \n",
    "plt.plot(CNN_model.history['acc'])  \n",
    "plt.plot(CNN_model.history['val_acc'])  \n",
    "plt.title('Model Accuracy')  \n",
    "plt.ylabel('Accuracy')  \n",
    "plt.xlabel('Epoch')  \n",
    "plt.legend(['train', 'validation'], loc='upper left')   \n",
    "\n",
    "# plotting model loss \n",
    "plt.subplot(212)  \n",
    "plt.plot(CNN_model.history['loss'])  \n",
    "plt.plot(CNN_model.history['val_loss'])  \n",
    "plt.title('Model Loss')  \n",
    "plt.ylabel('Loss')  \n",
    "plt.xlabel('Epoch')  \n",
    "plt.legend(['train', 'validation'], loc='upper left')  \n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
